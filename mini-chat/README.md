# Mini-Chat LLMaaS Cloud Temple

Ce script Python permet d'interagir avec les mod√®les de langage de la **plateforme LLMaaS Cloud Temple** via une interface en ligne de commande "jolie et agr√©able".

üìñ **Documentation compl√®te** : [docs.cloud-temple.com](https://docs.cloud-temple.com)

## Fonctionnalit√©s

- Choix interactif du mod√®le.
- Chat en mode streaming.
- Support des outils (tools) :
    - Horloge : Donne l'heure actuelle.
    - Calculatrice : √âvalue des expressions math√©matiques.
    - Lecture de fichier : Lit le contenu d'un fichier local.
    - Sauvegarde de contenu : Sauvegarde du texte dans un fichier.
    - Ex√©cution de commande shell : Ex√©cute des commandes shell (avec confirmation).
- Interface utilisateur am√©lior√©e avec la biblioth√®que `rich`.
- Aide int√©gr√©e et commande `/tools` pour lister les outils.
- Option pour d√©finir la taille maximale des tokens de la r√©ponse.
- Possibilit√© de d√©finir un **prompt syst√®me**.
- Mode debug pour afficher les payloads API.
- Affichage des statistiques de la requ√™te (tokens, vitesse).
- **Sauvegarde et chargement** de sessions de chat (param√®tres + historique) en JSON.
- Sauvegarde de l'historique en Markdown.

## Pr√©requis

- Python 3.8+
- Une cl√© API LLMaaS valide.

## Installation

1.  Clonez ce d√©p√¥t (si ce n'est pas d√©j√† fait).
2.  Naviguez vers le r√©pertoire `exemples/mini-chat/`.
3.  Cr√©ez un environnement virtuel (recommand√©) :
    ```bash
    python -m venv .venv
    source .venv/bin/activate  # Sur Linux/macOS
    # .venv\Scripts\activate    # Sur Windows
    ```
4.  Installez les d√©pendances :
    ```bash
    pip install -r requirements.txt
    ```
5.  Configurez vos identifiants API :
    - Copiez `.env.example` vers `.env`.
    - √âditez `.env` et renseignez votre `API_URL` et `API_KEY`.

        ```env
        API_URL="https://api.ai.cloud-temple.com/v1"
        API_KEY="votre_cle_api_ici"
        ```

## Utilisation

```bash
python mini_chat.py [OPTIONS]
```

**Options principales :**

- `--model TEXT` : Nom du mod√®le √† utiliser (ex: `gemma3:4b`).
- `--max-tokens INTEGER` : Max tokens pour la r√©ponse (d√©faut: 1024).
- `--temperature FLOAT` : Temp√©rature pour la g√©n√©ration (d√©faut: 0.7).
- `--system-prompt TEXT` ou `-sp TEXT`: Prompt syst√®me initial.
- `--debug / --no-debug` : Active/d√©sactive l'affichage des payloads API.
- `--api-url TEXT` : URL de l'API LLMaaS (√©crase `.env`).
- `--api-key TEXT` : Cl√© API LLMaaS (√©crase `.env`).
- `--load-session CHEMIN_FICHIER_JSON`: Charge une session de chat sauvegard√©e.
- `--autosave-json CHEMIN_FICHIER_JSON`: Sauvegarde automatiquement la session en JSON √† la fin.
- `--autosave-md CHEMIN_FICHIER_MD`: Sauvegarde automatiquement l'historique en Markdown √† la fin.
- `--godmode`: Active le mode GOD MODE (aucune confirmation pour les commandes shell).
- `--silent`: Mode silencieux (moins d'output, n'affiche pas les outils ni les statistiques).
- `--rules CHEMIN_FICHIER_MD`: Fichier Markdown de r√®gles √† ajouter au prompt syst√®me.
- `--prompt TEXT`: Prompt initial √† envoyer au LLM au d√©marrage.
- `--non-interactive`: Mode non interactif (termine apr√®s la premi√®re r√©ponse compl√®te du LLM). N'affiche pas le message de bienvenue.
- `--no-stream`: D√©sactive le streaming de la r√©ponse de l'IA.
- `--help` : Affiche l'aide.

**Commandes en cours de chat :**

- `/quit` ou `/exit` : Quitte le chat.
- `/history` : Affiche l'historique de la conversation.
- `/clear` : Efface l'historique (conserve les param√®tres de session comme le prompt syst√®me).
- `/model` : Change de mod√®le (r√©initialise l'historique, conserve le prompt syst√®me).
- `/system <prompt>` : D√©finit ou modifie le prompt syst√®me (r√©initialise l'historique).
- `/system_clear` : Supprime le prompt syst√®me (r√©initialise l'historique).
- `/save_session <fichier.json>` : Sauvegarde la session actuelle (param√®tres et historique).
- `/load_session <fichier.json>` : Charge une session (√©crase la session actuelle).
- `/savemd <fichier.md>` : Sauvegarde l'historique actuel en Markdown.
- `/tools` : Liste les outils disponibles et leur description (non affich√© en mode silencieux).
- `/smol` : Demande au mod√®le de condenser l'historique actuel en un prompt efficace.
- `/debug` : Active/d√©sactive le mode debug.
- `/silent`: Active/d√©sactive le mode silencieux.
- `/stream`: Active/d√©sactive le mode streaming pour la r√©ponse de l'IA.
- `/help` : Affiche l'aide d√©taill√©e des commandes.
