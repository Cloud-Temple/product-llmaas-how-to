# Mini-Chat LLMaaS

Interface en ligne de commande √©l√©gante pour interagir avec les mod√®les de langage de la plateforme LLMaaS, avec support complet du RAG (Retrieval-Augmented Generation).

## üöÄ D√©marrage Rapide

### 1. Installation

```bash
# Naviguez vers le r√©pertoire
cd exemples/mini-chat/

# Cr√©ez un environnement virtuel (recommand√©)
python -m venv .venv
source .venv/bin/activate  # Linux/macOS
# .venv\Scripts\activate    # Windows

# Installez les d√©pendances
pip install -r requirements.txt
```

### 2. Configuration

```bash
# Copiez le fichier de configuration
cp .env.example .env

# √âditez .env avec vos param√®tres
nano .env
```

**Configuration minimale** :
```env
API_URL="https://api.ai.cloud-temple.com/v1"
API_KEY="votre_cle_api_ici"
DEFAULT_MODEL="qwen3:30b-a3b"
```

### 3. D√©marrage de Qdrant (pour le RAG)

**Option A : Docker (recommand√©)**
```bash
# D√©marrage simple
docker run -p 6333:6333 qdrant/qdrant

# Ou avec persistance des donn√©es
docker run -p 6333:6333 -v $(pwd)/qdrant_storage:/qdrant/storage qdrant/qdrant
```

**Option B : Docker Compose**
```bash
# Utilisez le fichier fourni
docker-compose up -d
```

**Option C : Installation locale**
```bash
# Suivez les instructions sur https://qdrant.tech/documentation/quick-start/
```

### 4. Premier Lancement

```bash
# Lancement simple
python mini_chat.py

# Avec un mod√®le sp√©cifique
python mini_chat.py --model qwen3:4b

# Mode debug pour voir les d√©tails
python mini_chat.py --debug
```

## üéØ Fonctionnalit√©s Principales

### üí¨ Chat Intelligent
- **Streaming en temps r√©el** : R√©ponses affich√©es au fur et √† mesure
- **Historique persistant** : Navigation avec les fl√®ches ‚Üë/‚Üì
- **Autocompl√©tion** : 23 commandes avec Tab
- **Modes flexibles** : Debug, silencieux, non-interactif

### üõ†Ô∏è Outils Int√©gr√©s
- **üïí Horloge** : Heure actuelle
- **üßÆ Calculatrice** : Expressions math√©matiques
- **üìÅ Fichiers** : Lecture et sauvegarde
- **‚ö° Shell** : Ex√©cution de commandes (avec confirmation)
- **üîç RAG** : Recherche dans une base de connaissances vectorielle

### üß† RAG (Retrieval-Augmented Generation)
- **Ingestion automatique** : Commande `/embed` pour ajouter des documents
- **Recherche intelligente** : Seuils de similarit√© configurables
- **Activation flexible** : Mode automatique ou manuel
- **Diagnostic complet** : Gestion et monitoring de la base Qdrant

## üìã Guide d'Utilisation

### Configuration RAG

1. **D√©marrez Qdrant** (voir section D√©marrage Rapide)

2. **Configurez .env** :
```env
# Param√®tres Qdrant
QDRANT_URL="localhost"
QDRANT_PORT=6333
QDRANT_COLLECTION="minichat_rag"
EMBEDDING_MODEL="granite-embedding:278m"

# Param√®tres de chunking (en tokens)
RAG_CHUNK_SIZE=256
RAG_CHUNK_OVERLAP=50
```

3. **Ing√©rez des documents** :
```bash
# Dans le chat
/embed constitution.txt
```

4. **Activez le RAG** :
```bash
/rag on
```

### Commandes Essentielles

#### Gestion de Session
```bash
/model                    # Changer de mod√®le
/system <prompt>          # D√©finir un prompt syst√®me
/clear                    # Effacer l'historique
/save_session chat.json   # Sauvegarder la session
/load_session chat.json   # Charger une session
```

#### RAG et Documents
```bash
/embed <fichier>          # Ing√©rer un document
/rag on|off              # Activer/d√©sactiver le RAG
/rag_threshold 0.8       # Configurer le seuil de similarit√©
/qdrant_info             # Informations sur la base
/qdrant_list             # Lister les documents
```

#### Diagnostic et Debug
```bash
/context                 # √âtat de l'application
/context all             # Contexte complet + JSON
/debug                   # Mode debug on/off
/tools                   # Liste des outils disponibles
```

## ‚öôÔ∏è Options de Ligne de Commande

### Options Principales
```bash
python mini_chat.py [OPTIONS]

--model TEXT              # Mod√®le √† utiliser
--max-tokens INTEGER      # Limite de tokens (d√©faut: 8192)
--temperature FLOAT       # Temp√©rature (d√©faut: 0.7)
--system-prompt TEXT      # Prompt syst√®me initial
--debug / --no-debug      # Mode debug
```

### Options Avanc√©es
```bash
--api-url TEXT            # URL de l'API (√©crase .env)
--api-key TEXT            # Cl√© API (√©crase .env)
--non-interactive         # Mode non-interactif
--no-stream              # D√©sactiver le streaming
--silent                 # Mode silencieux
--godmode                # Pas de confirmation pour les commandes shell
```

### Options RAG
```bash
--qdrant-url TEXT         # URL Qdrant (d√©faut: localhost)
--qdrant-port INTEGER     # Port Qdrant (d√©faut: 6333)
--qdrant-collection TEXT  # Collection (d√©faut: minichat_rag)
--embedding-model TEXT    # Mod√®le d'embedding
```

### Options de Session
```bash
--load-session FILE       # Charger une session
--autosave-json FILE      # Sauvegarde auto en JSON
--autosave-md FILE        # Sauvegarde auto en Markdown
--rules FILE              # Fichier de r√®gles Markdown
--prompt TEXT             # Prompt initial
```

## üîß Configuration Avanc√©e

### Fichier .env Complet
```env
# API LLMaaS
API_URL="https://api.ai.cloud-temple.com/v1"
API_KEY="votre_cle_api_ici"
DEFAULT_MODEL="qwen3:30b-a3b"
MAX_TOKENS=8192

# Qdrant pour RAG
QDRANT_URL="localhost"
QDRANT_PORT=6333
QDRANT_COLLECTION="minichat_rag"
EMBEDDING_MODEL="granite-embedding:278m"

# Param√®tres de chunking (en tokens)
RAG_CHUNK_SIZE=256
RAG_CHUNK_OVERLAP=50
```

### Docker Compose pour Qdrant
```yaml
version: '3.8'
services:
  qdrant:
    image: qdrant/qdrant
    ports:
      - "6333:6333"
    volumes:
      - ./qdrant_storage:/qdrant/storage
    environment:
      - QDRANT__SERVICE__HTTP_PORT=6333
```

## üß™ Tests et Validation

### Test de l'Outil RAG
```bash
# Test unitaire de l'outil de recherche
python test_rag_tool.py

# Test avec une question constitutionnelle
echo "Qui peut r√©voquer le Premier ministre ?" | python mini_chat.py --model qwen3:4b --non-interactive
```

### Diagnostic de l'Installation
```bash
# V√©rifier la configuration
python mini_chat.py --debug
/context all

# Tester la connexion Qdrant
/qdrant_info
```

## üõ†Ô∏è D√©pannage

### Probl√®mes Courants

**Qdrant non accessible**
```bash
# V√©rifier que Qdrant fonctionne
curl http://localhost:6333/health

# Red√©marrer Qdrant
docker restart <container_id>
```

**RAG ne fonctionne pas**
```bash
# Dans le chat
/qdrant_info              # V√©rifier la connexion
/rag_threshold 0.7        # R√©duire le seuil
/context                  # Diagnostic complet
```

**Limite de contexte d√©pass√©e**
```bash
/context                  # Voir le diagnostic automatique
/smol                     # Condenser l'historique
/clear                    # Effacer l'historique
```

**Probl√®mes de mod√®les**
```bash
# Lister les mod√®les disponibles
python mini_chat.py --model ""

# Tester avec un mod√®le plus petit
python mini_chat.py --model qwen3:4b
```

## üìÅ Structure du Projet

```
exemples/mini-chat/
‚îú‚îÄ‚îÄ mini_chat.py              # Point d'entr√©e principal
‚îú‚îÄ‚îÄ api_client.py             # Client API LLMaaS
‚îú‚îÄ‚îÄ qdrant_utils.py           # Utilitaires Qdrant
‚îú‚îÄ‚îÄ tools_definition.py       # D√©finitions des outils
‚îú‚îÄ‚îÄ ui_utils.py               # Interface utilisateur
‚îú‚îÄ‚îÄ session_manager.py        # Gestion des sessions
‚îú‚îÄ‚îÄ rag_core.py               # Fonctions RAG
‚îú‚îÄ‚îÄ command_handler.py        # Gestionnaire de commandes
‚îú‚îÄ‚îÄ requirements.txt          # D√©pendances Python
‚îú‚îÄ‚îÄ .env.example              # Configuration exemple
‚îú‚îÄ‚îÄ docker-compose.yml        # Configuration Qdrant
‚îî‚îÄ‚îÄ test_rag_tool.py          # Tests unitaires
```

## üéØ Exemples d'Usage

### Chat Simple
```bash
python mini_chat.py --model qwen3:4b
> Bonjour ! Comment allez-vous ?
```

### RAG avec Constitution
```bash
# 1. D√©marrer Qdrant
docker run -p 6333:6333 qdrant/qdrant

# 2. Lancer mini-chat
python mini_chat.py --model qwen3:30b-a3b

# 3. Ing√©rer la constitution
/embed constitution.txt

# 4. Activer le RAG
/rag on

# 5. Poser une question
> Qui peut dissoudre l'Assembl√©e nationale selon la Constitution ?
```

### Mode Non-Interactif
```bash
echo "R√©sume-moi les articles 1 √† 5 de la Constitution" | \
python mini_chat.py --model qwen3:4b --non-interactive --no-stream
```

### Session Persistante
```bash
# Sauvegarder
python mini_chat.py --autosave-json ma_session.json

# Reprendre plus tard
python mini_chat.py --load-session ma_session.json
```

## üîÑ Mises √† Jour

### Version 1.3.1 (Actuelle)
- ‚úÖ **Bug critique r√©solu** : Outil de recherche vectorielle pleinement fonctionnel
- ‚úÖ **Gestion robuste des types** : Support universel des formats JSON
- ‚úÖ **Tests valid√©s** : 4/4 requ√™tes trait√©es sans erreur
- ‚úÖ **Documentation compl√®te** : Guide d'utilisation et d√©pannage

### Fonctionnalit√©s Pr√©c√©dentes
- üéØ **RAG intelligent** avec seuils configurables
- üîß **Diagnostic avanc√©** des probl√®mes de contexte
- üõ†Ô∏è **23 commandes** avec autocompl√©tion
- üìä **Gestion compl√®te de Qdrant** (listing, suppression, informations)

## üìû Support

Pour signaler un bug ou demander de l'aide :
1. Utilisez `/context all` pour obtenir le diagnostic complet
2. Consultez la section D√©pannage ci-dessus
3. V√©rifiez les logs en mode `--debug`

---

**Mini-Chat LLMaaS** - Interface de chat intelligente avec RAG pour la plateforme LLMaaS
