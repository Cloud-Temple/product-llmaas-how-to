# Cas d'Usage LLM as a Service - Cloud Temple

Ce rÃ©pertoire contient une collection d'exemples de code et de scripts dÃ©montrant les diffÃ©rentes fonctionnalitÃ©s et cas d'utilisation de **l'offre LLM as a Service (LLMaaS) de Cloud Temple**.

## ğŸ†• Changelog - DerniÃ¨res NouveautÃ©s

### Version 3.0.0 - 26 Janvier 2026

#### ğŸ’¬ **Mini-Chat v3.0 - Refonte Architecturale Majeure**
- ğŸ—ï¸ **Architecture Modulaire** : Refonte complÃ¨te du code (`Service`, `State`, `Config`, `CLI`) pour une robustesse et une maintenabilitÃ© maximales.
- ğŸ§  **RAG AvancÃ© & Stable** : Pipeline RAG entiÃ¨rement validÃ© (Ingestion -> Qdrant -> GÃ©nÃ©ration) avec gestion automatique des collections.
- ğŸ› ï¸ **Tool Calling Fiable** : Correction des problÃ¨mes de streaming avec les outils (calculatrice, shell, etc.) grÃ¢ce Ã  une gestion fine des chunks JSON.
- âš¡ **ModÃ¨le par DÃ©faut** : Passage Ã  `openai/gpt-oss-120b` pour des performances conversationnelles optimales.
- ğŸ§ª **Tests AutomatisÃ©s** : Ajout d'un script de scÃ©nario de test (`test_rag_scenario.py`) pour valider la configuration RAG en un clic.

#### ğŸ“¸ **PhotoAnalyzer - Support Qwen3 VL & Omni**
- ğŸ¤– **ModÃ¨les Multimodaux SOTA** : IntÃ©gration et validation des modÃ¨les **Qwen3-VL** (8b, 30b) et **Qwen3-Omni**.
- ğŸ”Œ **Standardisation API** : Mise Ã  jour du client pour utiliser le format standard `image_url`, assurant une compatibilitÃ© maximale.
- ğŸ“ **Documentation Enrichie** : Guide d'utilisation mis Ã  jour avec des exemples spÃ©cifiques pour les nouveaux modÃ¨les.

#### ğŸ§  **Qwen-Omni - CapacitÃ©s Multimodales Natives**
- ğŸš€ **Nouvel Exemple** : Ajout d'une dÃ©monstration dÃ©diÃ©e (`qwen_omni_demo`) illustrant les capacitÃ©s de comprÃ©hension simultanÃ©e du texte et des images.
- âœ¨ **Performance** : Temps de rÃ©ponse ultra-rapides et comprÃ©hension contextuelle de haut niveau.

#### ğŸ¥ **MedGemma - Analyse d'Images MÃ©dicales**
- ğŸ§¬ **SpÃ©cialisation** : Validation et mise Ã  jour bilingue de l'exemple d'analyse d'imagerie mÃ©dicale (radio, scanner) via le modÃ¨le expert `medgemma:27b`.

#### ğŸ”Œ **Simple MCP Demo - Protocole MCP SÃ©curisÃ©**
- ğŸŒ **Architecture DistribuÃ©e** : ImplÃ©mentation de rÃ©fÃ©rence du Model Context Protocol (MCP) sur HTTP/SSE.
- ğŸ”’ **SÃ©curitÃ© RenforcÃ©e** : Authentification par clÃ© API via middleware ASGI pur.
- ğŸ³ **Docker Ready** : DÃ©ploiement simplifiÃ© du serveur MCP via Docker Compose.
- ğŸ› **Debug & PÃ©dagogie** : Logs dÃ©taillÃ©s du protocole JSON-RPC et documentation du flux de session SSE.

#### ğŸ“Š **Status API Demo - Dashboard & Ã‰nergie**
- ğŸ“ˆ **Monitoring en Temps RÃ©el** : CrÃ©ation d'un tableau de bord pour surveiller l'Ã©tat de santÃ© de la plateforme et les performances des modÃ¨les (TTFB, tok/s).
- âš¡ **Energy Map Officielle** : IntÃ©gration des coefficients de consommation Ã©nergÃ©tique rÃ©els (kWh/Mtoken) mis Ã  jour au 26/01/2026.

### Version 2.2.1 - 25 Janvier 2026

#### ğŸ” **GetFact - Robustesse JSON & max_tokens 16k**
- ğŸ§± **Gestion des rÃ©ponses tronquÃ©es** : meilleure rÃ©sistance aux sorties incomplÃ¨tes (`finish_reason=length`) grÃ¢ce Ã  des consignes JSON-only et une stratÃ©gie de retry.
- ğŸ”¢ **Limite de gÃ©nÃ©ration augmentÃ©e** : valeur par dÃ©faut portÃ©e Ã  **16384 tokens** (config `.env` / `.env.example`) pour rÃ©duire la probabilitÃ© de troncature sur des chunks denses.
- ğŸ§  **Ontologies MÃ©tiers** : Documentation dÃ©taillÃ©e des 6 ontologies prÃªtes Ã  l'emploi (Droit, RH, DevOps, SÃ©curitÃ©, Infrastructure, InfogÃ©rance).

#### ğŸŒ **Translate - Traduction de documents volumineux**
- ğŸ“… **Date et Version** : Script mis Ã  jour au 25/01/2026 (v1.2.1).
- ğŸ§© **Chunking Intelligent** : Algorithme de dÃ©coupage respectant les structures de paragraphes et de phrases pour maintenir le sens.
- ğŸ’ **Support TranslateGemma** : Format de prompt spÃ©cifique et paramÃ¨tres optimisÃ©s pour les modÃ¨les Google TranslateGemma.
- ğŸ”— **CohÃ©rence Contextuelle** : SystÃ¨me de contexte glissant entre les chunks pour une traduction homogÃ¨ne du dÃ©but Ã  la fin du document.
- âœï¸ **Documentation** : Commentaires didactiques ajoutÃ©s pour expliquer les flux asynchrones et la gestion des langues ISO.

### Version 2.2.0 - Novembre 2025

#### ğŸ‘ï¸ **DeepSeek-OCR - Vision & Extraction** âœ¨ *NOUVEL EXEMPLE*
- ğŸ“„ **Conversion Markdown structurÃ©e** : Transforme n'importe quel document (PDF, image) en Markdown propre (tableaux, titres)
- ğŸ§® **Support MathÃ©matiques** : Transcription prÃ©cise des formules en LaTeX
- ğŸ“‘ **Traitement PDF multipages** : Conversion page par page des documents longs
- ğŸ–¼ï¸ **Optimisation intelligente** : PrÃ©traitement des images (zoom, conversion RGB) pour une lisibilitÃ© maximale

### Version 2.1.0 - Juillet 2025

#### ğŸ” **GetFact - Extracteur de Faits**
- âœ¨ **Support des modÃ¨les raisonneurs** : Gestion automatique des rÃ©ponses incluant des blocs de pensÃ©e (`<think>...</think>`)
- ğŸ› ï¸ **Parsing JSON robuste** : Extraction fiable du contenu JSON mÃªme depuis des rÃ©ponses malformÃ©es
- ğŸ› **Mode debug avancÃ©** : Logs dÃ©taillÃ©s incluant le dÃ©coupage prÃ©cis, les payloads JSON complets et les rÃ©ponses brutes de l'API


#### ğŸµ **Transkryptor - Transcription Audio**
- ğŸ”„ **RÃ©silience aux erreurs** : MÃ©canisme de retry avec backoff exponentiel pour une meilleure stabilitÃ©
- âœ¨ **Raffinement de transcription (`--rework`)** : Nouvelle option pour amÃ©liorer la transcription via un modÃ¨le de langage
- ğŸ“„ **Script `rework-only.py`** : Nouveau script dÃ©diÃ© pour raffiner des fichiers texte existants
- ğŸ”— **Contexte continu (`--rework-follow`)** : Maintien du contexte entre les lots pour une meilleure cohÃ©rence
- ï¿½ **Recommandations de qualitÃ©** : Configuration optimale basÃ©e sur des tests (20s pour contenu complexe, 10s pour dialogues)
- ğŸ“¦ **DÃ©pendances Ã©tendues** : Ajout de `tiktoken` et `langchain-text-splitters` pour un meilleur dÃ©coupage

#### ğŸ“ **Summarizer - SynthÃ¨se de Texte** âœ¨ *NOUVEL OUTIL*
- ğŸ†• **Outil complet de synthÃ¨se** : Nouveau script pour gÃ©nÃ©rer des synthÃ¨ses prÃ©cises de fichiers texte ou Markdown de n'importe quelle taille
- ğŸ§© **DÃ©coupage intelligent par tokens** : Utilise `tiktoken` pour un dÃ©coupage prÃ©cis respectant les limites des modÃ¨les
- âš¡ **Traitement parallÃ¨le par lots** : Optimisation de la vitesse avec traitement simultanÃ© des chunks
- ğŸ”— **ContinuitÃ© contextuelle** : Maintien du contexte entre les sections pour une synthÃ¨se cohÃ©rente
- ğŸ“ **Prompts configurables** : Support de diffÃ©rents types de synthÃ¨se (concis, dÃ©taillÃ©, points d'action, Q&A)
- ğŸ“– **Documentation complÃ¨te** : README franÃ§ais et anglais avec exemples d'usage dÃ©taillÃ©s

#### ğŸ“š **Exemples RAG (Retrieval-Augmented Generation)** âœ¨ *NOUVEAUX EXEMPLES*
- ğŸ†• **Simple RAG Demo** : Un script pÃ©dagogique pour comprendre les mÃ©canismes de base du RAG avec des vecteurs en mÃ©moire.
- ğŸ†• **RAG with Qdrant Demo** : Un exemple complet et conteneurisÃ© utilisant Qdrant comme base de donnÃ©es vectorielle pour des applications RAG plus robustes.

#### ğŸ’¬ **Mini-Chat - Chat avec RAG et Outils**
- ğŸ§  **Support RAG complet** : IntÃ©gration avec la base vectorielle Qdrant pour des rÃ©ponses augmentÃ©es par vos documents.
- ğŸ› ï¸ **Outils intÃ©grÃ©s** : Inclut calculatrice, horloge, accÃ¨s aux fichiers, exÃ©cution de commandes shell et recherche RAG.
- âš™ï¸ **Interface en ligne de commande avancÃ©e** : AutocomplÃ©tion, historique persistant, et gestion fine des sessions.
- ğŸš€ **Architecture v3.0** : Refonte complÃ¨te avec architecture modulaire robuste, gestion d'erreurs avancÃ©e et modÃ¨le par dÃ©faut `gpt-oss-120b`.

---

## Ã€ propos de LLMaaS Cloud Temple

L'API LLMaaS de Cloud Temple vous permet d'intÃ©grer facilement des modÃ¨les de langage dans vos applications. Elle est accessible via la Console Cloud Temple oÃ¹ vous pouvez gÃ©rer vos clÃ©s API, surveiller votre consommation et configurer vos paramÃ¨tres.

### AccÃ¨s rapide Ã  l'API

- **URL de base** : `https://api.ai.cloud-temple.com/v1/`
- **Authentification** : Header `Authorization: Bearer YOUR_API_KEY`
- **Format** : JSON (`Content-Type: application/json`)

### Endpoints principaux

- `/chat/completions` : GÃ©nÃ©ration de rÃ©ponses conversationnelles
- `/completions` : ComplÃ©tion de texte simple  
- `/models` : Liste des modÃ¨les disponibles

### Exemple de requÃªte cURL

```bash
curl -X POST "https://api.ai.cloud-temple.com/v1/chat/completions" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -d '{
    "model": "granite3.3:8b",
    "messages": [
      {
        "role": "user", 
        "content": "Salut ! Peux-tu te prÃ©senter en franÃ§ais ?"
      }
    ],
    "max_tokens": 200,
    "temperature": 0.7
  }'
```

### ParamÃ¨tres disponibles

| ParamÃ¨tre     | Type    | Description                               |
| ------------- | ------- | ----------------------------------------- |
| `model`       | string  | Le modÃ¨le Ã  utiliser                      |
| `messages`    | array   | Liste des messages de la conversation     |
| `max_tokens`  | integer | Nombre maximum de tokens Ã  gÃ©nÃ©rer        |
| `temperature` | float   | ContrÃ´le la crÃ©ativitÃ© (0.0-2.0)          |
| `top_p`       | float   | ContrÃ´le la diversitÃ© des rÃ©ponses        |
| `stream`      | boolean | Active le streaming de la rÃ©ponse         |
| `user`        | string  | Identifiant unique de l'utilisateur final |

## Structure des Exemples

Chaque exemple est organisÃ© dans son propre sous-rÃ©pertoire avec :
- Un fichier README.md expliquant l'objectif et le fonctionnement
- Les fichiers de code source nÃ©cessaires  
- Les fichiers de configuration (`.env.example`, `config.example.json`)
- Les donnÃ©es d'exemple le cas Ã©chÃ©ant

## ğŸ“¸ AperÃ§u Visuel

DÃ©couvrez les capacitÃ©s de l'API LLMaaS Cloud Temple Ã  travers ces captures d'Ã©cran des exemples en action :

### ğŸ‘ï¸ DeepSeek-OCR Vision & Extraction
![DeepSeek OCR Demo](./screenshoot/ocrdemo.png)
*Conversion d'un document complexe (PDF/Image) en Markdown structurÃ©, prÃ©servant tableaux et mise en forme*

### ğŸš€ Streaming en Temps RÃ©el
![Streaming Demo](./screenshoot/streaming_01.png)
*DÃ©monstration du streaming SSE avec affichage token par token et mÃ©triques de performance en temps rÃ©el*

### ğŸ’¬ Interface Chat Interactive
![Mini Chat Interface](./screenshoot/minichat_01.png)
*Interface de chat en ligne de commande avec sÃ©lection de modÃ¨le et configuration des paramÃ¨tres*

![Mini Chat Conversation](./screenshoot/minichat_02.png)
*Conversation en cours avec l'assistant IA, affichage des tokens et statistiques de performance*

![Mini Chat Tools](./screenshoot/minichat_03.png)
*Utilisation d'outils intÃ©grÃ©s (calculatrice, lecture de fichiers, commandes shell) dans le chat*

### ğŸµ Transcription Audio AvancÃ©e
![Transkryptor Interface](./screenshoot/transkryptor_01.png)
*Interface de transcription audio avec barre de progression et prÃ©visualisation en temps rÃ©el*

![Transkryptor Results](./screenshoot/transkryptor_02.png)
*RÃ©sultats de transcription avec dÃ©coupage intelligent et traitement par lots parallÃ¨les*

### ğŸ“¸ Analyse d'Images Multimodale
![PhotoAnalyzer Journal](./photoanalyzer/images/journal.png)
*Image originale d'un journal pour l'analyse multimodale*

![PhotoAnalyzer Vision 1](./screenshoot/journal1.png)
*PremiÃ¨re vision du modÃ¨le sur l'image du journal*

![PhotoAnalyzer Vision 2](./screenshoot/journal2.png)
*DeuxiÃ¨me vision du modÃ¨le sur l'image du journal*

### ğŸ“š DÃ©monstration RAG Simple
![Simple RAG Demo](./screenshoot/simple_rag.png)
*ExÃ©cution du script RAG simple, montrant les Ã©tapes de vectorisation, recherche et gÃ©nÃ©ration augmentÃ©e*

## Exemples Disponibles

### ğŸ‘ï¸ [DeepSeek-OCR Demo](./deepseek-ocr_demo/)
DÃ©monstration de la puissance du modÃ¨le DeepSeek-OCR (Janus-Pro) pour la conversion intelligente de documents visuels. Contrairement aux OCR classiques, il comprend la structure du document : tableaux complexes, hiÃ©rarchie des titres et formules mathÃ©matiques sont prÃ©servÃ©s et convertis en Markdown structurÃ©. Supporte les images et les PDF multipages.

### ğŸ§  [Qwen-Omni Demo](./qwen_omni_demo/)
Exemple d'utilisation du nouveau modÃ¨le **Qwen3-Omni**, fleuron de la multimodalitÃ© native. Ce modÃ¨le est capable de traiter et de raisonner simultanÃ©ment sur des entrÃ©es complexes mÃªlant texte et vision avec une fluiditÃ© exceptionnelle et une prÃ©cision accrue sur les dÃ©tails visuels.

### ğŸ¥ [MedGemma Analysis](./medgemma_analysis/)
Utilisation du modÃ¨le spÃ©cialisÃ© **MedGemma** pour l'analyse d'imagerie mÃ©dicale. Cet exemple dÃ©montre comment l'IA peut assister les professionnels de santÃ© dans la description de structures anatomiques et l'identification d'anomalies potentielles Ã  partir de radios ou de scanners.

### ğŸ“¸ [PhotoAnalyzer](./photoanalyzer/)
PhotoAnalyzer est un outil CLI Python avancÃ© pour l'analyse d'images utilisant l'API LLMaaS avec des modÃ¨les multimodaux. Il offre une interface utilisateur soignÃ©e avec modes debug, formats de sortie multiples, et support de diffÃ©rents types de prompts d'analyse spÃ©cialisÃ©s.

### ğŸ” [GetFact](./getfact/) 
Extracteur de faits et relations intelligent utilisant l'API LLMaaS. Capable d'extraire automatiquement entitÃ©s, Ã©vÃ©nements, relations, attributs, informations temporelles et spatiales d'un texte. Supporte les ontologies mÃ©tier spÃ©cialisÃ©es (Droit, RH, DevOps, SÃ©curitÃ©, Infrastructure, InfogÃ©rance) pour une extraction contextuelle optimisÃ©e.

### ğŸ“ [Summarizer](./summarizer/)
Outil de synthÃ¨se de texte avancÃ© utilisant l'API LLMaaS. GÃ©nÃ¨re des synthÃ¨ses prÃ©cises de fichiers texte ou Markdown de n'importe quelle taille avec dÃ©coupage intelligent par tokens, traitement parallÃ¨le par lots, et continuitÃ© contextuelle entre les sections.

### ğŸ“š [Simple RAG Demo](./simple_rag_demo/)
DÃ©monstrateur RAG pÃ©dagogique pour illustrer le fonctionnement du Retrieval-Augmented Generation. Utilise l'API LLMaaS pour l'embedding et la gÃ©nÃ©ration, avec stockage des vecteurs en mÃ©moire pour une comprÃ©hension claire du processus.

### ğŸ“š [RAG with Qdrant Demo](./rag-granite-qdrant-demo/)
DÃ©monstrateur RAG complet et conteneurisÃ© utilisant Qdrant comme base de donnÃ©es vectorielle. L'API LLMaaS est utilisÃ©e pour l'embedding des documents et la gÃ©nÃ©ration de rÃ©ponses augmentÃ©es.

### ğŸ“ [List Models](./list_models/)
Script avancÃ© pour lister tous les modÃ¨les disponibles via l'API LLMaaS avec leurs dÃ©tails, spÃ©cifications et statuts. Le script inclut une catÃ©gorisation fonctionnelle des modÃ¨les (Langage GÃ©nÃ©raliste, Embedding, Vision, OCR, etc.) pour faciliter leur sÃ©lection selon l'usage prÃ©vu.

### ğŸš€ [Streaming Demo](./streaming-demo/)
Exemple minimal pour dÃ©montrer le streaming en temps rÃ©el avec l'API LLMaaS. Montre l'activation du streaming SSE (Server-Sent Events), l'affichage token par token, et le calcul des mÃ©triques de performance.

### ğŸ’¬ [Mini Chat](./mini-chat/)
Client de chat en ligne de commande interactif (v3.0) refondu pour une stabilitÃ© maximale. Il supporte non seulement les conversations standards avec les modÃ¨les LLM, mais intÃ¨gre Ã©galement un **systÃ¨me RAG complet** via Qdrant et **des outils intÃ©grÃ©s** (calculatrice, shell, gestion de fichiers, etc.). Cette nouvelle version offre une architecture modulaire et une gestion robuste des tool calls en streaming.

### ğŸ“Š [Status API Demo](./status_api_demo/)
Script de dÃ©monstration pour l'API publique de statut de la plateforme. Il permet de surveiller l'Ã©tat de santÃ© global de LLMaaS, de rÃ©cupÃ©rer les mÃ©triques de performance en temps rÃ©el (TTFB, dÃ©bit) et d'estimer prÃ©cisÃ©ment la consommation Ã©nergÃ©tique des requÃªtes par modÃ¨le.

### ğŸ§ª [Test API Models](./test_api_models/)
Script Python pour tester et comparer des modÃ¨les LLM via API avec configuration externe, dÃ©couverte dynamique, sÃ©lection de modÃ¨les, gestion d'erreurs et rÃ©sumÃ© des performances.

### ğŸ§ª [Test API Models PowerShell](./test_api_models_powershell/)
Version PowerShell du script de test des modÃ¨les, similaire Ã  la version Python mais adaptÃ©e aux environnements Windows.

### ğŸ¤ [Whisper](./whisper/)
Exemple d'utilisation de l'API de transcription audio (ASR) avec client Python, dÃ©montrant la conversion audio vers texte.

### ğŸŒ [Translate](./translate/)
Script Python pour traduire des fichiers texte par segments, utilisant un modÃ¨le LLM et conservant le contexte entre les segments pour des traductions cohÃ©rentes.

### ğŸµ [Transkryptor](./transkryptor/)
Outil CLI Python avancÃ© pour la transcription de fichiers audio volumineux, utilisant le dÃ©coupage intelligent, le traitement par lots parallÃ¨les, la normalisation audio et une interface utilisateur soignÃ©e.

### ğŸ£ [Exemples PÃ©dagogiques (Simples)](./)
SÃ©rie d'exemples minimalistes conÃ§us pour apprendre Ã  utiliser les fonctions de base de l'API :
- **[Simple RAG Demo](./simple_rag_demo/)** : Les bases du RAG avec vecteurs en mÃ©moire.
- **[Simple Tool Calling](./simple_tool_calling/)** : Comment connecter le LLM Ã  une fonction Python (calculatrice).
- **[Simple Vision](./simple_vision/)** : Analyse d'image basique avec des modÃ¨les multimodaux.
- **[Simple TTS](./simple_tts/)** : SynthÃ¨se vocale rapide et lecture audio.
- **[Simple Translate](./simple_translate/)** : Traduction de texte optimisÃ©e avec TranslateGemma.
- **[Simple MCP Demo](./simple_mcp_demo/)** : Utilisation du Model Context Protocol (MCP) en architecture distribuÃ©e HTTP/SSE sÃ©curisÃ©e.

## Configuration

Chaque exemple inclut un fichier `.env.example` que vous devez copier vers `.env` et remplir avec vos paramÃ¨tres :

```bash
# Dans chaque dossier d'exemple
cp .env.example .env
# Ã‰ditez .env avec votre clÃ© API Cloud Temple
```

## PrÃ©requis

- Python 3.7+
- ClÃ© API LLMaaS Cloud Temple
- AccÃ¨s Ã  la Console Cloud Temple

## Support

Pour toute question concernant l'API LLMaaS Cloud Temple, consultez la documentation officielle ou contactez le support Cloud Temple.

ğŸ“– **Documentation complÃ¨te** : [docs.cloud-temple.com](https://docs.cloud-temple.com)

## Licence

Ces outils sont sous licence GPL 3.0 - voir le fichier [LICENSE](LICENSE) pour plus de dÃ©tails.
