# Clé API pour le service LLMaaS
# Renommez ce fichier en .env et remplissez la valeur
LLMAAS_API_KEY="VOTRE_CLE_API_ICI"

# URL de l'API LLMaaS (optionnel, peut être surchargé par argument CLI)
# LLMAAS_API_URL="https://api.ai.cloud-temple.com/v1"

# Modèle LLM à utiliser pour la traduction (optionnel, peut être surchargé par argument CLI)
# Si non défini, la valeur par défaut du script sera utilisée (actuellement qwen3:14b).
# LLMAAS_TRANSLATE_MODEL="votre_modele_de_traduction_prefere"

# Langue cible par défaut (optionnel, code ISO 639-1, ex: 'en', 'fr')
# Si non défini ici ou par argument CLI, le script demandera cet argument.
# LLMAAS_TARGET_LANGUAGE="fr"

# Nombre maximum de tokens par chunk de traduction (optionnel)
# Si non défini, la valeur par défaut du script sera utilisée (actuellement 2048).
# LLMAAS_MAX_TOKENS="2048"

# Taille des chunks en mots (optionnel)
# Si non défini, la valeur par défaut du script sera utilisée (actuellement 300).
# LLMAAS_CHUNK_SIZE_WORDS="300"

# Prompt système par défaut (optionnel)
# Si non défini, la valeur par défaut du script sera utilisée.
# LLMAAS_SYSTEM_PROMPT="Vous êtes un traducteur IA avancé. Traduisez le texte suivant avec précision et fluidité."

# Répertoire de sortie par défaut pour les fichiers traduits (optionnel)
# Si non défini, la valeur par défaut du script sera utilisée (actuellement "translated_files").
# LLMAAS_OUTPUT_DIR="my_translations"
