# GetFact - Extracteur de Faits et Relations

![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)
![LLMaaS](https://img.shields.io/badge/LLMaaS-Compatible-green.svg)

Ce script permet d'extraire automatiquement les faits et les relations entre faits d'un fichier texte en utilisant l'API LLMaaS de Cloud Temple. Il peut optionnellement utiliser une ontologie fournie pour am√©liorer la pr√©cision de l'extraction et sauvegarde les r√©sultats au format JSON ou YAML.

## üåü Fonctionnalit√©s

- **Extraction intelligente** : Identifie automatiquement les entit√©s, √©v√©nements, relations, attributs, informations temporelles et spatiales
- **Support d'ontologie** : Utilise optionnellement un fichier d'ontologie (JSON/YAML/TXT) pour guider l'extraction
- **D√©coupage intelligent** : Traite les documents longs en les d√©coupant en chunks logiques
- **Formats de sortie** : Sauvegarde au format JSON ou YAML avec structure organis√©e
- **Mode interactif** : Validation/modification possible de l'extraction de chaque chunk
- **Interface riche** : Affichage color√© avec barres de progression et r√©sum√©s d√©taill√©s
- **Configuration flexible** : Param√®tres configurables via ligne de commande et variables d'environnement
- **Support des mod√®les raisonneurs** : G√®re automatiquement les r√©ponses des mod√®les qui incluent des blocs de pens√©e (ex: `<think>...</think>`) avant le JSON.
- **Parsing JSON robuste** : Extrait de mani√®re fiable le contenu JSON m√™me √† partir de r√©ponses malform√©es ou contenant du texte parasite.

## üß† Ontologies Sp√©cialis√©es

GetFact inclut 6 ontologies m√©tier pr√™tes √† l'emploi pour une extraction contextuelle optimis√©e :

| Ontologie | Domaine | Fichier | Usage |
|-----------|---------|---------|-------|
| üèõÔ∏è **Juridique** | Droit, contentieux, compliance | `ontologie_droit.yaml` | Contrats, jugements, conformit√© |
| üë• **RH** | Ressources humaines, SIRH | `ontologie_rh.yaml` | CV, entretiens, mobilit√© |
| üíª **D√©veloppement** | DevOps, ing√©nierie logicielle | `ontologie_developpement.yaml` | Code, architectures, m√©triques |
| üîí **S√©curit√©** | Cybers√©curit√©, RSSI | `ontologie_securite_logique.yaml` | Incidents, vuln√©rabilit√©s, audits |
| ‚òÅÔ∏è **Infrastructure** | Cloud, datacenters, r√©seaux | `ontologie_infrastructure_cloud.yaml` | Serveurs, co√ªts, performance |
| ü§ù **Infog√©rance** | Services manag√©s, ITIL | `ontologie_infogerance.yaml` | SLA, tickets, processus |

### Exemples d'usage par domaine

```bash
# Analyse juridique - contrat commercial
python getfact.py --file contrat.txt --ontology ontologie_droit.yaml

# RH - analyse de CV
python getfact.py --file cv_candidat.txt --ontology ontologie_rh.yaml

# S√©curit√© - rapport d'incident
python getfact.py --file incident_secu.txt --ontology ontologie_securite_logique.yaml

# Infrastructure - rapport de performance
python getfact.py --file perf_report.txt --ontology ontologie_infrastructure_cloud.yaml
```

## üìã Types de Faits Extraits

| Type           | Description                                       | Exemples                                  |
| -------------- | ------------------------------------------------- | ----------------------------------------- |
| **Entit√©s**    | Personnes, organisations, lieux, objets, concepts | Jean Dupont, Cloud Temple, Paris, serveur |
| **√âv√©nements** | Actions, processus, incidents, situations         | r√©union, d√©ploiement, incident, formation |
| **Relations**  | Connexions entre entit√©s                          | travaille pour, situ√© √†, d√©pend de        |
| **Attributs**  | Propri√©t√©s, caract√©ristiques, qualit√©s            | couleur, taille, performance, statut      |
| **Temporel**   | Dates, dur√©es, s√©quences temporelles              | 2025-06-04, 2 heures, avant/apr√®s         |
| **Spatial**    | Localisations, positions relatives                | nord de, √† c√¥t√© de, datacenter            |

## üöÄ Installation

```bash
# Installation des d√©pendances
pip install -r requirements.txt

# Configuration
cp .env.example .env
# Editez le fichier .env avec vos param√®tres
```

## ‚öôÔ∏è Configuration

### Variables d'environnement (.env)

```bash
# Cl√© API LLMaaS (obligatoire)
LLMAAS_API_KEY=your_api_key_here

# URL de l'API LLMaaS
LLMAAS_API_URL=https://api.ai.cloud-temple.com/v1

# Mod√®le √† utiliser pour l'extraction
LLMAAS_GETFACT_MODEL=qwen3:14b

# Format de sortie par d√©faut (json ou yaml)
LLMAAS_OUTPUT_FORMAT=json

# Nombre maximum de tokens pour les r√©ponses
LLMAAS_MAX_TOKENS=4096

# Taille des chunks en mots
LLMAAS_CHUNK_SIZE_WORDS=500

# R√©pertoire de sortie
LLMAAS_OUTPUT_DIR=extracted_facts

# Prompt syst√®me personnalis√© optionnel
LLMAAS_CUSTOM_PROMPT=""
```

## üí° Utilisation

### Utilisation basique

```bash
# Extraction simple d'un fichier texte
python getfact.py --file document.txt

# Avec ontologie pour guider l'extraction
python getfact.py --file document.txt --ontology exemple_ontologie.yaml

# Sortie en format YAML
python getfact.py --file document.txt --output-format yaml
```

### Options avanc√©es

```bash
# Mode interactif avec validation
python getfact.py --file document.txt --interactive

# Types de faits sp√©cifiques
python getfact.py --file document.txt --fact-types entities events relationships

# Mod√®le et param√®tres personnalis√©s
python getfact.py --file document.txt --model granite3:8b --max-tokens 2048

# Mode debug pour voir le d√©coupage
python getfact.py --file document.txt --debug

# Avec prompt syst√®me personnalis√©
python getfact.py --file document.txt --custom-prompt "Concentrez-vous sur les aspects financiers et les montants"
```

### Prompt syst√®me personnalis√©

La fonctionnalit√© de prompt personnalis√© permet d'ajouter des instructions sp√©cifiques pour guider l'extraction selon vos besoins :

```bash
# Focus sur la conformit√© r√©glementaire
python getfact.py --file audit_report.txt \
  --custom-prompt "Portez une attention particuli√®re aux non-conformit√©s, r√©f√©rences r√©glementaires et actions correctives"

# Extraction orient√©e performance
python getfact.py --file system_logs.txt \
  --custom-prompt "Identifiez prioritairement les m√©triques de performance, temps de r√©ponse et goulots d'√©tranglement"

# Analyse de sentiment dans les retours clients
python getfact.py --file feedback_clients.txt \
  --custom-prompt "Extrayez les √©motions, sentiments positifs/n√©gatifs et niveau de satisfaction client"
```

**Via variable d'environnement :**
```bash
export LLMAAS_CUSTOM_PROMPT="Focalisez sur les risques op√©rationnels et financiers"
python getfact.py --file risk_assessment.txt
```

### Aide et version

```bash
# Afficher l'aide compl√®te
python getfact.py --help

# Afficher la version
python getfact.py --version
```

## üìÑ Formats de Fichiers

### Fichier d'entr√©e
- **Formats support√©s** : TXT, MD, ou tout fichier texte UTF-8
- **Taille** : D√©coupage automatique en chunks pour les gros documents
- **Encodage** : UTF-8 recommand√©

### Ontologie (optionnelle)
L'ontologie peut √™tre fournie dans plusieurs formats :

#### JSON
```json
{
  "entities": {
    "person": ["nom", "pr√©nom", "titre"],
    "organization": ["nom", "type", "secteur"],
    "location": ["ville", "pays", "r√©gion"]
  },
  "relationships": {
    "employment": ["travaille pour", "employ√© par"],
    "location": ["situ√© √†", "bas√© √†"],
    "hierarchy": ["dirige", "supervise"]
  }
}
```

#### YAML
```yaml
entities:
  person:
    - nom
    - pr√©nom  
    - titre
  organization:
    - nom
    - type
    - secteur
relationships:
  employment:
    - "travaille pour"
    - "employ√© par"
```

#### TXT (format libre)
```
Types d'entit√©s importantes :
- Personnes : nom, pr√©nom, fonction
- Organisations : nom, secteur d'activit√©
- Lieux : ville, pays

Relations √† identifier :
- Hi√©rarchie : qui dirige qui
- Localisation : o√π se trouve quoi
- Temporalit√© : quand se passe quoi
```

## üìä Format de Sortie

### Structure JSON/YAML

```json
{
  "facts": [
    {
      "id": "fact_1",
      "type": "entity",
      "content": "Jean Dupont est ing√©nieur DevOps",
      "entities_involved": ["Jean Dupont", "ing√©nieur DevOps"],
      "confidence": 0.95,
      "source_text": "Jean Dupont, ing√©nieur DevOps chez Cloud Temple",
      "context": "Pr√©sentation de l'√©quipe",
      "chunk_source": 1
    }
  ],
  "relationships": [
    {
      "id": "rel_1",
      "type": "employment",
      "source_fact_id": "fact_1",
      "target_fact_id": "fact_2",
      "relationship_description": "Jean Dupont travaille pour Cloud Temple",
      "confidence": 0.90,
      "chunk_source": 1
    }
  ],
  "summary": {
    "total_facts": 42,
    "total_relationships": 15,
    "fact_types_count": {
      "entity": 18,
      "event": 12,
      "relationship": 8,
      "attribute": 4
    },
    "main_entities": ["Jean Dupont", "Cloud Temple", "Paris"],
    "key_themes": ["infrastructure", "√©quipe", "projet"],
    "chunks_processed": 3
  },
  "metadata": {
    "extraction_version": "1.0.0",
    "timestamp": "2025-06-04T20:15:30",
    "source_file": "document.txt"
  }
}
```

## üéØ Exemples d'Usage

### Analyse de CV
```bash
python getfact.py --file cv_candidat.txt --fact-types entities attributes temporal
```

### Analyse de rapport d'incident
```bash
python getfact.py --file incident_report.txt --ontology exemple_ontologie.yaml --interactive
```

### Extraction pour base de connaissances
```bash
python getfact.py --file documentation.md --output-format yaml --chunk-size-words 800
```

## üîß Mod√®les Recommand√©s

| Mod√®le           | Usage              | Avantages                          |
| ---------------- | ------------------ | ---------------------------------- |
| `qwen3:14b`      | Usage g√©n√©ral      | Bon √©quilibre pr√©cision/vitesse    |
| `granite3:8b`    | Documents courts   | Rapide, efficace                   |
| `deepseek-r1:7b` | Analyse complexe   | Raisonnement avanc√©                |
| `cogito:7b`      | Textes sp√©cialis√©s | Excellent pour domaines techniques |

## üìà Optimisation des Performances

### Param√®tres recommand√©s selon la taille du document

| Taille document | chunk-size-words | max-tokens | Mod√®le      |
| --------------- | ---------------- | ---------- | ----------- |
| < 1000 mots     | 500              | 2048       | granite3:8b |
| 1000-5000 mots  | 400              | 3072       | qwen3:14b   |
| > 5000 mots     | 300              | 4096       | qwen3:14b   |

### Conseils d'optimisation
- **Ontologie** : Utilisez une ontologie sp√©cialis√©e pour votre domaine
- **Chunks** : R√©duisez la taille pour des textes denses en informations
- **Mode interactif** : Utilisez-le pour affiner votre approche sur de petits √©chantillons
- **Types de faits** : Limitez aux types pertinents pour votre cas d'usage

## üêõ D√©pannage

### Erreurs courantes

**Erreur de cl√© API**
```
Erreur: La variable d'environnement LLMAAS_API_KEY n'est pas d√©finie.
```
‚Üí V√©rifiez votre fichier `.env` et la valeur de `LLMAAS_API_KEY`

**R√©ponse JSON invalide**
```
Attention: R√©ponse JSON invalide pour le chunk 2
```
‚Üí Le script est maintenant plus robuste et tente d'extraire le JSON m√™me si la r√©ponse est malform√©e. Si l'erreur persiste, elle peut √™tre due √† une r√©ponse tronqu√©e par l'API. Dans ce cas, essayez d'augmenter la valeur de `--max-tokens`.

**Timeout API**
```
Erreur API pour le chunk 1: timeout
```
‚Üí Le mod√®le peut √™tre surcharg√©, r√©essayez ou changez de mod√®le

### Mode debug
Utilisez `--debug` pour un diagnostic avanc√©. Cette option active des logs tr√®s d√©taill√©s, incluant :
- Le d√©coupage pr√©cis du texte en chunks.
- Le `payload` JSON complet envoy√© √† l'API pour chaque chunk.
- La r√©ponse brute (code de statut, en-t√™tes et corps) re√ßue de l'API.

```bash
# Activer le mode de d√©bogage pour une analyse approfondie
python getfact.py --file document.txt --debug
```

## ü§ù Contribution

Cet exemple fait partie du projet LLMaaS de Cloud Temple. Pour toute suggestion d'am√©lioration :

1. Ouvrez une issue pour discuter des changements propos√©s
2. Respectez le style de code et les conventions existantes
3. Testez vos modifications avec diff√©rents types de documents
4. Documentez les nouvelles fonctionnalit√©s

## üìÑ Licence

Ce script est distribu√© sous la m√™me licence que le projet LLMaaS principal.

---

**Cloud Temple - LLMaaS Team**  
*Intelligence Artificielle Souveraine et S√©curis√©e*
