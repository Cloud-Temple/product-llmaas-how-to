# Script Python Avanc√© pour Tester l'API LLMaaS Cloud Temple

üìñ **Documentation compl√®te** : [docs.cloud-temple.com](https://docs.cloud-temple.com)

## Objectif
Ce script Python (`test_api_models.py`) permet de tester et comparer les r√©ponses de diff√©rents mod√®les de langage (LLM) accessibles via l'**API LLMaaS Cloud Temple**. Il offre des fonctionnalit√©s avanc√©es pour la configuration, la s√©lection des mod√®les, la personnalisation des requ√™tes et l'affichage des r√©sultats. Il s'agit d'une adaptation du script PowerShell original.

## Fonctionnalit√©s
1.  **Configuration Externe :** Lit l'endpoint de l'API et le token d'authentification depuis un fichier `config.json`. Permet √©galement de d√©finir des valeurs par d√©faut pour les passes, la temp√©rature, le nombre max de tokens et le timeout.
2.  **D√©couverte Dynamique des Mod√®les :** R√©cup√®re automatiquement la liste des mod√®les disponibles depuis l'endpoint `/models` de l'API.
3.  **S√©lection des Mod√®les :** Permet de sp√©cifier les mod√®les √† tester via l'argument `--models` (liste d'IDs s√©par√©s par des virgules). Si omis, tous les mod√®les disponibles sont test√©s.
4.  **Personnalisation du Prompt :** Le prompt envoy√© aux mod√®les peut √™tre d√©fini via l'argument `--prompt`.
5.  **Tests Multiples :** Effectue un nombre configurable de passes (requ√™tes) pour chaque mod√®le (argument `--passes`) pour √©valuer la coh√©rence et la performance.
6.  **Param√®tres de G√©n√©ration :** Permet de contr√¥ler la temp√©rature (`--temperature`) et le nombre maximum de tokens (`--max-tokens`) pour les requ√™tes.
7.  **Mode Debug :** Une option `--debug` active l'affichage d'informations d√©taill√©es sur les requ√™tes, les r√©ponses et les erreurs, y compris le corps des r√©ponses d'erreur de l'API.
8.  **Gestion d'Erreurs Am√©lior√©e :** Intercepte les erreurs API (par ex. 403 Forbidden) et tente d'extraire et d'afficher le message d√©taill√© fourni dans la r√©ponse JSON (par ex. "Prompt blocked for security reasons") sans planter le script.
9.  **Sortie Color√©e :** Utilise des couleurs (via la biblioth√®que `rich`) pour distinguer les informations, les succ√®s et les √©checs dans la console.
10. **Tableau R√©capitulatif :** Affiche un r√©sum√© final (via `rich.table`) comparant les performances (succ√®s, erreurs, temps moyen, temps total, tokens/seconde, etc.) de chaque mod√®le test√©.
11. **Parall√©lisme des Mod√®les :** Permet de tester plusieurs mod√®les simultan√©ment pour acc√©l√©rer le processus (argument `--parallel-models`).
12. **Parall√©lisme des Requ√™tes :** Permet d'envoyer plusieurs requ√™tes en parall√®le √† un m√™me mod√®le pour tester sa capacit√© √† g√©rer la charge (argument `--parallel-requests`).
13. **Statistiques D√©taill√©es :** Affiche des informations sur les tokens par seconde et les d√©tails du backend (si fournis par l'API) pour chaque r√©ponse.

## Pr√©requis
-   Python 3.7+
-   Les biblioth√®ques list√©es dans `requirements.txt` (principalement `requests` et `rich`). Installez-les avec :
    ```bash
    pip install -r requirements.txt
    ```
-   Un fichier `config.json` dans le m√™me r√©pertoire que le script, contenant au minimum :
    ```json
    {
        "api": {
            "endpoint": "URL_DE_VOTRE_API",
            "token": "VOTRE_TOKEN_BEARER"
        }
    }
    ```
    Optionnellement, une section `defaults` peut √™tre ajout√©e pour surcharger les valeurs par d√©faut du script :
    ```json
    {
        "api": { ... },
        "defaults": {
            "passes": 5,
            "temperature": 0.8,
            "max_tokens": 512,
            "timeout": 60
        }
    }
    ```

## Utilisation

**Syntaxe de base :**
```bash
python test_api_models.py [Arguments...]
```
**Arguments principaux :**
*   `--models "<id1>,<id2>..."` : Liste des IDs de mod√®les √† tester. Si omis, teste tous les mod√®les disponibles.
*   `--prompt "<votre_prompt>"` : Le prompt √† envoyer.
*   `--passes <nombre>` : Nombre de requ√™tes par mod√®le.
*   `--temperature <valeur>` : Temp√©rature pour la g√©n√©ration (ex: 0.7).
*   `--max-tokens <nombre>` : Nombre maximum de tokens en sortie.
*   `-e`, `--endpoint <URL>` : URL compl√®te de l'endpoint API √† utiliser (ex: `http://preprod.api.ai.cloud-temple.com/v1`). Surcharge la valeur du fichier de configuration si sp√©cifi√©.
*   `--debug` : Active l'affichage d√©taill√©.
*   `--config-file <chemin>` : Utilise un fichier de configuration sp√©cifique.
*   `--parallel-models <nombre>` : Nombre de mod√®les √† tester en parall√®le (d√©faut: 1).
*   `--parallel-requests <nombre>` : Nombre de requ√™tes √† envoyer en parall√®le pour chaque mod√®le (d√©faut: 1).

**Exemples :**

1.  **Tester tous les mod√®les avec les param√®tres par d√©faut :**
    ```bash
    python test_api_models.py
    ```

2.  **Tester des mod√®les sp√©cifiques (`cogito:3b` et `qwen3:4b`) avec 5 passes :**
    ```bash
    python test_api_models.py --models "cogito:3b,qwen3:4b" --passes 5
    ```

3.  **Tester tous les mod√®les avec un prompt personnalis√© et en mode debug :**
    ```bash
    python test_api_models.py --prompt "Explique la photosynth√®se en une phrase." --debug
    ```

4.  **Tester un mod√®le avec une temp√©rature et un nombre de tokens sp√©cifiques :**
    ```bash
    python test_api_models.py --models "llama3.1" --temperature 0.5 --max-tokens 100
    ```

5.  **Utiliser un fichier de configuration sp√©cifique :**
    ```bash
    python test_api_models.py --config-file "../autre_config.json"
    ```
6.  **Utiliser un endpoint sp√©cifique via la ligne de commande :**
    ```bash
    python test_api_models.py --endpoint "http://mon-autre-api.local/v1" --models "cogito:3b"
    ```

7.  **Tester 3 mod√®les en parall√®le, chacun avec 2 requ√™tes en parall√®le :**
    ```bash
    python test_api_models.py --models "cogito:3b,qwen3:4b,gemma3:1b" --passes 5 --parallel-models 3 --parallel-requests 2
    ```

8.  **Tester tous les mod√®les, 2 mod√®les √† la fois en parall√®le, avec 3 passes par mod√®le, chaque passe ayant 4 requ√™tes en parall√®le :**
    ```bash
    python test_api_models.py --passes 3 --parallel-models 2 --parallel-requests 4
    ```

## Notes
-   La gestion d'erreur tente d'extraire les d√©tails des r√©ponses JSON d'erreur de l'API, mais le format exact peut varier selon l'impl√©mentation de l'API.
-   L'utilisation d'un grand nombre de requ√™tes parall√®les (`--parallel-requests`) combin√©e √† un grand nombre de mod√®les parall√®les (`--parallel-models`) peut solliciter fortement votre machine et l'API cible. Utilisez avec discernement.
